{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"D76-optimizer_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cpZ2c_Ynqh7s","colab_type":"text"},"source":["# 作業重點:\n","\n","(1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n","\n","(2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"]},{"cell_type":"markdown","metadata":{"id":"pr-X-ol7qh7t","colab_type":"text"},"source":["# 作業目標:\n","    \n","    取得各種優化器的運算結果"]},{"cell_type":"code","metadata":{"id":"_oaMC338qh70","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"45f2613c-3c2a-4688-f0c4-f5708cbd406a","executionInfo":{"status":"ok","timestamp":1563728208905,"user_tz":-480,"elapsed":5080,"user":{"displayName":"Abao JiunYiYang","photoUrl":"https://lh6.googleusercontent.com/-wfNeAHjpo-A/AAAAAAAAAAI/AAAAAAAAAs4/fa-T5hmo2Vs/s64/photo.jpg","userId":"03267307845025036989"}}},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import os\n","from keras import optimizers\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BX8nyDATqh7-","colab_type":"code","colab":{}},"source":["#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n","import tensorflow as tf\n","gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n","sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"soOmUfmbqh8I","colab_type":"code","colab":{}},"source":["\n","'''\n","   宣告並設定\n","   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n","   epochs ：訓練次數\n","   \n","''' \n","\n","batch_size = 32\n","num_classes = 10\n","epochs = 20\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0ZYijmUqh8M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"07909ba6-d0fd-4da2-d8e5-247a841a4ca9","executionInfo":{"status":"ok","timestamp":1563728524737,"user_tz":-480,"elapsed":1807,"user":{"displayName":"Abao JiunYiYang","photoUrl":"https://lh6.googleusercontent.com/-wfNeAHjpo-A/AAAAAAAAAAI/AAAAAAAAAs4/fa-T5hmo2Vs/s64/photo.jpg","userId":"03267307845025036989"}}},"source":["\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OjNotLaRqh8Z","colab_type":"code","colab":{}},"source":["#    第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n"," \n","model = Sequential()\n","\n","#   第二步：構建網絡層\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense( 10)) # 輸出結果是10個類別，所以維度是10   \n","model.add(Activation('softmax')) # 最後一層用softmax作為激活函數"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUk8Xivlqh8e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c615efb9-10a5-4b4d-e381-a2f3287f9dc7","executionInfo":{"status":"ok","timestamp":1563728525804,"user_tz":-480,"elapsed":743,"user":{"displayName":"Abao JiunYiYang","photoUrl":"https://lh6.googleusercontent.com/-wfNeAHjpo-A/AAAAAAAAAAI/AAAAAAAAAs4/fa-T5hmo2Vs/s64/photo.jpg","userId":"03267307845025036989"}}},"source":["# 模型建立完成後，統計參數總量\n","print(\"Total Parameters：%d\" % model.count_params())"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Total Parameters：1250858\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EoRJ277Uqh8o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":763},"outputId":"1a295293-ccf7-4e42-b4fe-11a9f7a157b6","executionInfo":{"status":"ok","timestamp":1563728528651,"user_tz":-480,"elapsed":752,"user":{"displayName":"Abao JiunYiYang","photoUrl":"https://lh6.googleusercontent.com/-wfNeAHjpo-A/AAAAAAAAAAI/AAAAAAAAAs4/fa-T5hmo2Vs/s64/photo.jpg","userId":"03267307845025036989"}}},"source":["# 輸出模型摘要資訊\n","model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dyXcwhTqh8w","colab_type":"code","colab":{}},"source":["#第三步編譯\n"," '''\n"," SGD(隨機梯度下降) - Arguments\n","lr: float >= 0. Learning rate.\n","momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n","decay: float >= 0. Learning rate decay over each update.\n","nesterov: boolean. Whether to apply Nesterov momentum.\n","'''\n","\n","'''\n","RMSprop- Arguments\n","lr: float >= 0. Learning rate.\n","rho: float >= 0.\n","epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n","decay: float >= 0. Learning rate decay over each update.\n","'''\n","\n","'''\n","Example:\n","opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","'''\n","opt = optimizers.Adam(lr=0.01, decay=1e-6, momentum=0.9)\n","# opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","# opt = optimizers.RMSprop(lr=0.01, decay=1e-6, rho=0.9, epsilon=0.05)\n","model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"83ZVMcTcqh85","colab_type":"code","colab":{}},"source":["# 資料正規化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGj5b2bjqh89","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":571},"outputId":"411ed7a1-d37a-404e-8897-009b95b1488c","executionInfo":{"status":"error","timestamp":1563728686257,"user_tz":-480,"elapsed":41178,"user":{"displayName":"Abao JiunYiYang","photoUrl":"https://lh6.googleusercontent.com/-wfNeAHjpo-A/AAAAAAAAAAI/AAAAAAAAAs4/fa-T5hmo2Vs/s64/photo.jpg","userId":"03267307845025036989"}}},"source":["# 是否要做資料處理\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    history=model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    print('')\n","        \n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","    history=model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)   \n","\n","'''\n","   第四步：訓練\n","   .fit的一些參數\n","   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n","   epochs ：訓練次數\n","   shuffle：是否把數據隨機打亂之後再進行訓練\n","   validation_split：拿出百分之多少用來做交叉驗證\n","   verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\n","''' \n","    "],"execution_count":24,"outputs":[{"output_type":"stream","text":["Using real-time data augmentation.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n","50000/50000 [==============================] - 12s 237us/step - loss: 2.3041 - acc: 0.0984 - val_loss: 2.3043 - val_acc: 0.1000\n","Epoch 2/20\n","50000/50000 [==============================] - 12s 234us/step - loss: 2.3038 - acc: 0.1011 - val_loss: 2.3051 - val_acc: 0.1000\n","Epoch 3/20\n","50000/50000 [==============================] - 12s 234us/step - loss: 2.3039 - acc: 0.0972 - val_loss: 2.3032 - val_acc: 0.1000\n","Epoch 4/20\n","19424/50000 [==========>...................] - ETA: 6s - loss: 2.3039 - acc: 0.0999"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7bb57997adb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m               shuffle=True)   \n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m '''\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"x39j3zZSqh9K","colab_type":"code","colab":{}},"source":["# Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = os.path.join(save_dir, model_name)\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTMnj-I6qh9Q","colab_type":"code","colab":{}},"source":["#    第六步：輸出\n","import numpy \n","\n","print ( \" test set \" )\n","scores = model.evaluate(x_test,y_test,batch_size=200,verbose= 0)\n","print ( \"\" )\n","print ( \" The test loss is \", scores[0])\n","\n","\n","result = model.predict(x_test,batch_size=200,verbose= 0)\n","\n","result_max = numpy.argmax(result, axis = 1 )\n","test_max = numpy.argmax(y_test, axis = 1 )\n","\n","result_bool = numpy.equal(result_max, test_max)\n","true_num = numpy.sum(result_bool)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RilnhHiCqh9y","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Plot training & validation accuracy values\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Valiidation'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Valiidation'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1I6pJHqIQr4s","colab_type":"text"},"source":["### [SGD] \n","\n","Test loss: 0.6840170444488526\n","\n","Test accuracy: 0.7724\n","\n","\n","### [RMSprop]\n","\n","Test loss: 0.8217618954658509\n","\n","Test accuracy: 0.724"]},{"cell_type":"code","metadata":{"id":"P8IIl5e7Qxt1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}